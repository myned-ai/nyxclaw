# Avatar Chat Server - Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# OpenAI Configuration (Required for sample_openai agent)
# =============================================================================
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o-realtime-preview
OPENAI_VOICE=alloy

# Voice Activity Detection (VAD) settings for interruption sensitivity
# Lower threshold = more sensitive to speech (0.0-1.0, default: 0.5)
OPENAI_VAD_THRESHOLD=0.5
# How long to wait for silence before ending turn (ms, default: 300)
OPENAI_VAD_SILENCE_DURATION_MS=300
# Audio padding before detected speech (ms, default: 300)
OPENAI_VAD_PREFIX_PADDING_MS=300
# VAD type: server_vad (silence-based), semantic_vad (meaning-based), or none (manual)
OPENAI_VAD_TYPE=server_vad
# Transcription model for user speech
OPENAI_TRANSCRIPTION_MODEL=  gpt-4o-transcribe
# Transcription language (helps prevent hallucinations)
OPENAI_TRANSCRIPTION_LANGUAGE=en
# Noise reduction: near_field (close mic) or far_field (room mic)
OPENAI_NOISE_REDUCTION=near_field
# Voice speed (0.25 to 1.5, where 1.0 is normal speed)
OPENAI_VOICE_SPEED=1.0

# =============================================================================
# Gemini Configuration (Required for sample_gemini agent)
# =============================================================================
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-2.5-flash-native-audio-preview-12-2025
# Available voices: Puck, Charon, Kore, Fenrir, Aoede, Leda, Orus, Zephyr
GEMINI_VOICE=Kore
# Thinking mode: budget in tokens (0=disabled, -1=dynamic, 1-32768=fixed budget)
# Only works with models that support thinking (e.g., gemini-2.5-flash, gemini-2.5-pro)
GEMINI_THINKING_BUDGET=-1
# Enable Google Search grounding for up-to-date information
GEMINI_GOOGLE_SEARCH_GROUNDING=false
# Proactive audio: model can decide not to respond if input is not relevant
GEMINI_PROACTIVE_AUDIO=false
# Context window compression: enables sessions longer than 15 minutes
GEMINI_CONTEXT_WINDOW_COMPRESSION=true

# =============================================================================
# ZeroClaw Configuration (Required for sample_zeroclaw)
# =============================================================================
ZEROCLAW_BASE_URL=http://127.0.0.1:5555
ZEROCLAW_WS_TOKEN=
ZEROCLAW_MODEL=zeroclaw:main
# Optional stable user ID for session continuity
ZEROCLAW_USER_ID=your-zeroclaw-api-token-here
# Thinking mode hint for response style: off, minimal, default
# Note: this is applied as system-prompt guidance (latency/verbosity hint).
ZEROCLAW_THINKING_MODE=minimal
# faster-whisper model id ("small.en" recommended; also: tiny.en, base.en, medium.en)
ZEROCLAW_STT_MODEL=small.en
# Silero VAD thresholds for ONNX STT
ZEROCLAW_STT_VAD_START_THRESHOLD=0.60
ZEROCLAW_STT_VAD_END_THRESHOLD=0.35
ZEROCLAW_STT_VAD_MIN_SILENCE_MS=280
# Whisper initial prompt — primes decoder with expected vocabulary (e.g. character names)
STT_INITIAL_PROMPT=Nyx, Hi Nyx, Hey Nyx, stop, yes, no, okay, hello, goodbye, thank you, please
# ONNX TTS model directory (Kokoro ONNX)
ZEROCLAW_TTS_ONNX_MODEL_DIR=./pretrained_models/kokoro_onnx
ZEROCLAW_TTS_ONNX_PROVIDER=auto
ZEROCLAW_TTS_VOICE_NAME=af_jessica
ZEROCLAW_TTS_VOICE_PATH=
ZEROCLAW_TTS_ONNX_TEMPERATURE=0.7
ZEROCLAW_TTS_ONNX_LSD_STEPS=1
ZEROCLAW_TTS_CHUNK_DURATION_MS=40
# VITS expressiveness knobs (Piper TTS)
# noise_scale: audio variation (0=flat/deterministic, 1=expressive). Model default: 0.667
ZEROCLAW_TTS_NOISE_SCALE=0.75
# noise_w_scale: phoneme duration variation (0=robotic rhythm, 1=natural). Model default: 0.8
ZEROCLAW_TTS_NOISE_W_SCALE=0.8
# length_scale: speech speed (<1=faster, >1=slower). Default: 1.0
ZEROCLAW_TTS_LENGTH_SCALE=0.95

# =============================================================================
# OpenClaw Configuration (Required for sample_openclaw)
# =============================================================================
OPENCLAW_API_TOKEN=your-openclaw-api-token-here
OPENCLAW_BASE_URL=http://127.0.0.1:19001
OPENCLAW_MODEL=openclaw:main
# Optional stable user ID for session continuity
OPENCLAW_USER_ID=your-openclaw-api-token-here
# Optional gateway routing overrides
OPENCLAW_SESSION_KEY=
OPENCLAW_AGENT_ID=
# Thinking mode hint for response style: off, minimal, default
# Note: this is applied as system-prompt guidance (latency/verbosity hint).
OPENCLAW_THINKING_MODE=minimal
# faster-whisper model id ("small.en" recommended; also: tiny.en, base.en, medium.en)
OPENCLAW_STT_MODEL=small.en
# Silero VAD thresholds for ONNX STT
OPENCLAW_STT_VAD_START_THRESHOLD=0.60
OPENCLAW_STT_VAD_END_THRESHOLD=0.35
OPENCLAW_STT_VAD_MIN_SILENCE_MS=280
# Whisper initial prompt — primes decoder with expected vocabulary (e.g. character names)
# STT_INITIAL_PROMPT=Nyx, Hi Nyx, Hey Nyx, stop, yes, no, okay, hello
# ONNX TTS model directory (Kokoro ONNX)
OPENCLAW_TTS_ONNX_MODEL_DIR=./pretrained_models/kokoro_onnx
OPENCLAW_TTS_ONNX_PROVIDER=auto
OPENCLAW_TTS_VOICE_NAME=af_jessica
OPENCLAW_TTS_VOICE_PATH=
OPENCLAW_TTS_ONNX_TEMPERATURE=0.7
OPENCLAW_TTS_ONNX_LSD_STEPS=1
OPENCLAW_TTS_CHUNK_DURATION_MS=40
# VITS expressiveness knobs (Piper TTS)
# noise_scale: audio variation (0=flat/deterministic, 1=expressive). Model default: 0.667
OPENCLAW_TTS_NOISE_SCALE=0.75
# noise_w_scale: phoneme duration variation (0=robotic rhythm, 1=natural). Model default: 0.8
OPENCLAW_TTS_NOISE_W_SCALE=0.8
# length_scale: speech speed (<1=faster, >1=slower). Default: 1.0
OPENCLAW_TTS_LENGTH_SCALE=0.95

# =============================================================================
# Agent Configuration
# =============================================================================
AGENT_TYPE=sample_openai  # Options: sample_openai, sample_gemini, sample_openclaw, sample_zeroclaw, remote
AGENT_URL=  # For remote agent: ws://agent-service:8080/ws

# =============================================================================
# Assistant Configuration
# =============================================================================
ASSISTANT_INSTRUCTIONS=You are a helpful and friendly AI assistant. Be concise in your responses.

# Knowledge base source (optional): local file path or URL
# Examples: data/knowledge.md or https://example.com/knowledge.md
KNOWLEDGE_BASE_SOURCE=

# =============================================================================
# Audio2Expression Model Configuration (ONNX CPU-only)
# =============================================================================
# Path to the ONNX model for CPU inference
ONNX_MODEL_PATH=./pretrained_models/wav2arkit/wav2arkit_cpu.onnx

# =============================================================================
# Server Configuration
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
DEBUG=false

# =============================================================================
# Authentication Configuration
# Generate AUTH_SECRET_KEY with: openssl rand -hex 32
# =============================================================================
AUTH_ENABLED=true
AUTH_SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32
AUTH_TOKEN_TTL=3600
AUTH_ALLOWED_ORIGINS=https://myned.ai,https://www.myned.ai
AUTH_ENABLE_RATE_LIMITING=true
